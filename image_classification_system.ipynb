{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:56.646194600Z",
     "start_time": "2024-02-16T13:26:56.642582600Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F  # a module in PyTorch that contains functions like activation functions, loss functions, and more."
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#  this line of code sets up a pipeline that first converts images to the tensor format suitable for neural networks and then normalizes their pixel values to help with the efficient training of the network.\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] )"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:56.653606400Z",
     "start_time": "2024-02-16T13:26:56.646194600Z"
    }
   },
   "id": "1fc05a78ebac9254",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    ToTensor()\n",
      "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:56.659083Z",
     "start_time": "2024-02-16T13:26:56.650332300Z"
    }
   },
   "id": "d08f528369f0cd84",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# CIFAR-10 dataset contains 60,000 color images of 32x32 pixels, evenly divided into 10 classes (like cars, birds, cats, etc.), with 6,000 images per class. The dataset is split into 50,000 training images and 10,000 test images.\n",
    "\n",
    "# Load the training portion of the CIFAR-10 dataset, download it to the specified folder if it's not there already, and apply the specified preprocessing steps to each image in the dataset.\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:57.368751700Z",
     "start_time": "2024-02-16T13:26:56.658033400Z"
    }
   },
   "id": "f2b50040163648b4",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#  this line of code sets up an efficient way to iterate through the training data, providing batches of four images at a time, shuffled for each epoch to improve learning, and using two parallel workers to ensure that data is always ready for the model to train on, minimizing downtime. \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:57.378865400Z",
     "start_time": "2024-02-16T13:26:57.375771200Z"
    }
   },
   "id": "20f9f73ee02c2441",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# for the test set:\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:57.922275200Z",
     "start_time": "2024-02-16T13:26:57.376775600Z"
    }
   },
   "id": "8643b3a19568aabb",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# The Net class represents a specific architecture for a Convolutional Neural Network (CNN).\n",
    "# 3 channels for RGB color images.\n",
    "# 6 filters apply, 6 different feature maps, where each feature map is essentially a 2D array that represents some features detected in the input.\n",
    "# 5 the size of the kernel.\n",
    "# The second convolutional layer takes the 6 channels produced by conv1 as input and produces 16 output channels, also with a 5x5 kernel.\n",
    "# A max pooling layer with a 2x2 window and stride of 2. \n",
    "# fc1, fc2, fc3: \n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)  # The output of the last pooling layer is flattened to transform it into a vector suitable for input into the fully connected layers.\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:57.929162100Z",
     "start_time": "2024-02-16T13:26:57.923400800Z"
    }
   },
   "id": "1a0fef479667533d",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "net = Net()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:57.935926900Z",
     "start_time": "2024-02-16T13:26:57.929162100Z"
    }
   },
   "id": "c8311b776c34886c",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:57.939558800Z",
     "start_time": "2024-02-16T13:26:57.936854500Z"
    }
   },
   "id": "97c989ca787390f8",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T13:26:57.943246500Z",
     "start_time": "2024-02-16T13:26:57.940681100Z"
    }
   },
   "id": "baccda0bed88cdb3",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "324b7ea8c3ce5cdd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
