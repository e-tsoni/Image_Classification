{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# A Classification Example Using a Simple CNN (with CIFAR-10 dataset)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a63b3ef1da03a28c"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:14:36.882945500Z",
     "start_time": "2024-02-16T16:14:34.982006500Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset prerequisites\n",
    "These lines of code set up a pipeline that first converts images to the tensor format suitable for neural networks and then normalizes their pixel values to help with the efficient training of the network.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d181ab0b084a91e9"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))] )\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:14:36.890967200Z",
     "start_time": "2024-02-16T16:14:36.882945500Z"
    }
   },
   "id": "1fc05a78ebac9254",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "CIFAR-10 dataset contains 60,000 color images of 32x32 pixels, evenly divided into 10 classes (like cars, birds, cats, etc.), with 6,000 images per class. The dataset is split into 50,000 training images and 10,000 test images.\n",
    "\n",
    "Below, we load the training portion of the CIFAR-10 dataset, download it to the specified folder if it's not there already, and apply the specified preprocessing steps to each image in the dataset.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f86b417592d20454"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2b50040163648b4",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "This line of code sets up an efficient way to iterate through the training data, providing batches of four images at a time, shuffled for each epoch to improve learning, and using two parallel workers to ensure that data is always ready for the model to train on, minimizing downtime. \n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e615a7c44443c72"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:14:37.592460300Z",
     "start_time": "2024-02-16T16:14:37.585973Z"
    }
   },
   "id": "20f9f73ee02c2441",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Apply same steps for the test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1ba271e03741d3ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8643b3a19568aabb",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Net Class\n",
    "The Net class represents a specific architecture for a Convolutional Neural Network (CNN).\n",
    "- 3 channels for RGB color images.\n",
    "- 6 filters apply, 6 different feature maps, where each feature map is essentially a 2D array that represents some features detected in the input.\n",
    "- 5 the size of the kernel.\n",
    "- The second convolutional layer takes the 6 channels produced by conv1 as input and produces 16 output channels, also with a 5x5 kernel.\n",
    "- A max pooling layer with a 2x2 window and stride of 2. \n",
    "- fc1, fc2, fc3: fully connected layers\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a5da6f998cec884"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)  # The output of the last pooling layer is flattened to transform it into a vector suitable for input into the fully connected layers.\n",
    "        x = F.relu(self.fc1(x))  # apply the relu function after nn.Linear fully connected layer 1\n",
    "        x = F.relu(self.fc2(x))  # # apply the relu function after nn.Linear fully connected layer 2\n",
    "        x = self.fc3(x)  # outputs 10 classes\n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:14:38.164010500Z",
     "start_time": "2024-02-16T16:14:38.162997600Z"
    }
   },
   "id": "1a0fef479667533d",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "Initialize an Net() object:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d1763b57bc27fdb"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "net = Net()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:14:38.172555600Z",
     "start_time": "2024-02-16T16:14:38.165046Z"
    }
   },
   "id": "c8311b776c34886c",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Cross-entropy loss** is a frequently employed loss function. Effectively combines a log softmax layer and the negative log likelihood (NLL) loss in one single class. This simplification reduces the complexity of the model's architecture and speeds up the computation, since it's more efficient to compute both operations at once rather than separately. It's designed to handle multi-class classification problems directly, without the need for manually encoding targets into a one-hot format. \n",
    "\n",
    "**Stochastic Gradient Descent**, is a fundamental and widely used optimization algorithm in training neural networks. It is a preferred choice due to its simplicity, efficiency, and effectiveness in a wide range of scenarios. It provides a good starting point for optimization and can be enhanced with additional features like momentum and learning rate scheduling to improve performance. Despite the development of more advanced optimization algorithms, SGD remains a fundamental tool in deep learning.\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "374c4567a368aec8"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Choose a loss function and an optimizer.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "epochs = 20  # An epoch represents one complete pass through the entire training dataset. \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:14:38.176621900Z",
     "start_time": "2024-02-16T16:14:38.172555600Z"
    }
   },
   "id": "97c989ca787390f8",
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Training\n",
    "\n",
    "Train the CNN and calculate the losses:\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fed20d823934754"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "epoch_losses = []  # List to store loss of each epoch\n",
    "for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0  # At the start of each epoch, the running loss is reset to 0. This variable will accumulate the loss from each batch in the dataset, allowing you to calculate the average loss for the epoch.\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        # Before calculating the new gradients, existing gradients are reset to zero. Gradients accumulate by default, for correct parameter updates during backpropagation, but we need to clear them before computing gradients for the next batch.\n",
    "        optimizer.zero_grad()  # zero the parameter gradients\n",
    "        # The model processes the inputs through its forward method to produce predictions (outputs)\n",
    "        outputs = net(inputs)\n",
    "        # The loss function (criterion), which measures how well the model's predictions match the actual labels, is applied to compute the loss for the current batch.\n",
    "        loss = criterion(outputs, labels)\n",
    "        #  calculates the gradient of the loss function with respect to the model parameters by backpropagation. These gradients are used to adjust the model's parameters in the direction that minimally reduces the loss.\n",
    "        loss.backward()\n",
    "        # This applies the gradients computed by loss.backward() to update the model's parameters. The optimizer is responsible for adjusting the parameters based on the gradients to minimize the loss function.\n",
    "        optimizer.step()\n",
    "        # Adds the loss of the current batch to the running loss.\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    # After processing all batches in the dataset for the epoch, the average loss is printed.\n",
    "    epoch_loss = running_loss / len(trainloader)\n",
    "    epoch_losses.append(epoch_loss)  # Append the average loss for this epoch to the list\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {epoch_loss}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "baccda0bed88cdb3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Plotting the loss\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs+1), epoch_losses, marker='o', linestyle='-', color='blue')\n",
    "plt.title('Epoch vs Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:28:21.794441900Z",
     "start_time": "2024-02-16T16:28:21.790243Z"
    }
   },
   "id": "324b7ea8c3ce5cdd",
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate the Model\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "593675227210be57"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "correct = 0  # This initializes a counter for the number of predictions that the model gets right.\n",
    "total = 0  # This initializes a counter for the total number of predictions made (or the total number of labels in the test dataset).\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:28:21.801086400Z",
     "start_time": "2024-02-16T16:28:21.794386700Z"
    }
   },
   "id": "2ddf92e4df8989b3",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "with torch.no_grad():  # we do not need to calculate gradients during this operation. Since we're only evaluating the model and not training it, we don't need gradients, which saves memory and computation.\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)  # This adds the number of labels in the current batch to the total count of labels. It effectively counts the number of test images processed so far.\n",
    "        correct += (predicted == labels).sum().item()  # This calculates the number of correct predictions in the current batch by comparing predicted with labels. If a prediction matches the true label, it's counted as correct. .sum().item() adds up all the correct predictions to get a single number.\n",
    "\n",
    "print(f\"Accuracy on the test set: {(100 * correct / total):.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7c43514801946b7e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# This line defines a variable PATH that stores the file path where the model's state dictionary should be saved. The file extension .pth is commonly used for PyTorch model files, but it's not a requirement; you could use another extension if you prefer. \n",
    "PATH = './model/cifar_net.pth'\n",
    "\n",
    "# net.state_dict(): This method returns the model's state dictionary. The state dictionary is a Python dictionary object that maps each layer to its parameter tensor. Notably, the state dictionary contains weights and biases of the model layers, but it does not contain the model architecture itself. This means that when you load the model from this file, you'll need to have the model class (Net in your case) defined in your code.\n",
    "\n",
    "# Save the model\n",
    "torch.save(net.state_dict(), PATH)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:28:28.020847400Z",
     "start_time": "2024-02-16T16:28:28.014876100Z"
    }
   },
   "id": "2b917f045ac1e1af",
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Use the Model for New Input"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d41274bb0b08b081"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load the model\n",
    "net = Net()\n",
    "net.load_state_dict(torch.load(PATH))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dfca62ae6470cdc6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "net.eval()\n",
    "# Define the transformation\n",
    "transform_im = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),  # Resize the image to 32x32 pixels\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # These were the normalization values used during training\n",
    "])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:28:28.031894600Z",
     "start_time": "2024-02-16T16:28:28.027883Z"
    }
   },
   "id": "d7249300b50c4847",
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load and transform the image\n",
    "image_path = './imgs_input/bird.jpg'  # Update this to the path of your image\n",
    "image = Image.open(image_path)\n",
    "image = transform_im(image)\n",
    "image = image.unsqueeze(0)  # Add a batch dimension\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:28:28.071988500Z",
     "start_time": "2024-02-16T16:28:28.031894600Z"
    }
   },
   "id": "a1e81734da4dcc12",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Predict the class\n",
    "outputs = net(image)\n",
    "_, predicted = torch.max(outputs, 1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:28:28.073090400Z",
     "start_time": "2024-02-16T16:28:28.056097700Z"
    }
   },
   "id": "787b259d0e1e97b5",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-16T16:28:28.073090400Z",
     "start_time": "2024-02-16T16:28:28.061898100Z"
    }
   },
   "id": "60817d7479afde64",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "print(f'Predicted class: {cifar10_classes[predicted[0]]}')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a25dde9d20395c7",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "deea1bc07e50db6a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
